{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'data.csv'\n",
        "heart_data = pd.read_csv(file_path)\n",
        "\n",
        "# Drop 'id' and 'dataset' columns as they are not useful for prediction\n",
        "heart_data.drop(columns=['id', 'dataset'], inplace=True)\n",
        "\n",
        "# Handle categorical columns with Label Encoding\n",
        "label_cols = ['sex', 'cp', 'restecg', 'exang', 'slope', 'thal','fbs']\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for col in label_cols:\n",
        "    heart_data[col] = heart_data[col].astype(str)  # Ensure column is string before encoding\n",
        "    heart_data[col] = label_encoder.fit_transform(heart_data[col])\n",
        "\n",
        "# Handle missing values\n",
        "imputer_median = SimpleImputer(strategy='median')\n",
        "imputer_mode = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "# Impute median for numerical columns\n",
        "num_cols = ['trestbps', 'chol', 'thalch', 'oldpeak', 'ca']\n",
        "heart_data[num_cols] = imputer_median.fit_transform(heart_data[num_cols])\n",
        "\n",
        "# Impute most frequent for categorical columns\n",
        "cat_cols = ['slope', 'thal']\n",
        "heart_data[cat_cols] = imputer_mode.fit_transform(heart_data[cat_cols])\n",
        "\n",
        "# Check target distribution and apply SMOTE for class balancing\n",
        "X = heart_data.drop(columns=['num'])\n",
        "y = heart_data['num']\n",
        "\n",
        "X.isna().sum()\n"
      ],
      "metadata": {
        "id": "-t9Jvj_5sBs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "QztFPai1stX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to take user input for prediction\n",
        "def predict_heart_disease():\n",
        "    print(\"Please enter the following values to predict heart disease:\")\n",
        "\n",
        "    # Collecting inputs for each feature\n",
        "    age = float(input(\"Age: \"))\n",
        "    sex = int(input(\"Sex (0 = female, 1 = male): \"))\n",
        "    cp = int(input(\"Chest Pain Type (0, 1, 2, or 3): \"))\n",
        "    trestbps = float(input(\"Resting Blood Pressure: \"))\n",
        "    chol = float(input(\"Serum Cholesterol: \"))\n",
        "    fbs = int(input(\"Fasting Blood Sugar (1 = true, 0 = false): \"))\n",
        "    restecg = int(input(\"Resting Electrocardiographic Results (0, 1, or 2): \"))\n",
        "    thalch = float(input(\"Max Heart Rate Achieved: \"))\n",
        "    exang = int(input(\"Exercise Induced Angina (1 = yes, 0 = no): \"))\n",
        "    oldpeak = float(input(\"ST Depression: \"))\n",
        "    slope = int(input(\"Slope of the Peak Exercise ST Segment (0, 1, or 2): \"))\n",
        "    ca = float(input(\"Number of Major Vessels Colored by Fluoroscopy (0-3): \"))\n",
        "    thal = int(input(\"Thalassemia (0, 1, 2, or 3): \"))\n",
        "\n",
        "    # Create a numpy array from the input values\n",
        "    input_data = np.array([[age, sex, cp, trestbps, chol, fbs, restecg, thalch, exang, oldpeak, slope, ca, thal]])\n",
        "\n",
        "    # Make a prediction using the trained model\n",
        "    prediction = clf.predict(input_data)\n",
        "\n",
        "    # Output the result\n",
        "    if prediction[0] == 0:\n",
        "        print(\"Prediction: No heart disease\")\n",
        "    else:\n",
        "        print(f\"Prediction: Heart disease severity level {prediction[0]}\")\n",
        "\n",
        "# Example call to the prediction function\n",
        "predict_heart_disease()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "4RLOtPABtbZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the trained model\n",
        "model_filename = 'heart_disease_model.pkl'\n",
        "joblib.dump(clf, model_filename)\n",
        "\n",
        "# Download the model file\n",
        "print(f\"Model saved as {model_filename}\")\n"
      ],
      "metadata": {
        "id": "ShBnkcysuTI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x0xy4PDnuVcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heart_data.sample(5)"
      ],
      "metadata": {
        "id": "iQn5Fno_tRDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heart_data['slope'].value_counts()"
      ],
      "metadata": {
        "id": "p-tRQzWrJt-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.sample(3)"
      ],
      "metadata": {
        "id": "RcelobS_KQQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create sample from x  2 row for every class and git ther y\n",
        "\n",
        "# Create an empty list to store the sampled rows and their corresponding target values\n",
        "sampled_rows = []\n",
        "sampled_y = []\n",
        "\n",
        "# Iterate through the unique classes in y\n",
        "for class_label in y.unique():\n",
        "  # Get the indices of rows belonging to the current class\n",
        "  class_indices = y[y == class_label].index\n",
        "\n",
        "  # Randomly select 2 rows from the current class, if enough rows are available.\n",
        "  if len(class_indices) >= 1:\n",
        "    sampled_indices = np.random.choice(class_indices, size=1, replace=False)\n",
        "  else:\n",
        "    sampled_indices = class_indices\n",
        "\n",
        "  # Append the sampled rows and their target values to the lists.\n",
        "  for index in sampled_indices:\n",
        "    sampled_rows.append(X.loc[index].tolist())\n",
        "    sampled_y.append(y.loc[index])\n",
        "\n",
        "\n",
        "# Convert the list of sampled rows to a DataFrame\n",
        "sampled_X = pd.DataFrame(sampled_rows, columns=X.columns)\n",
        "\n",
        "\n",
        "\n",
        "print(sampled_y)\n",
        "\n"
      ],
      "metadata": {
        "id": "LqlWK1GsKcA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_X"
      ],
      "metadata": {
        "id": "sIoVpQBvLBhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i want to put sampled_X and sampled_y in dataframe\n",
        "sampled_df = pd.DataFrame(sampled_X)\n",
        "sampled_df['num'] = sampled_y\n",
        "print(sampled_df)\n"
      ],
      "metadata": {
        "id": "3tflO0pbOgAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: concat sampled_X and sampeled_y in datadframe\n",
        "\n",
        "sampled_df = pd.concat([sampled_X, pd.DataFrame({'num': sampled_y})], axis=1)\n",
        "sampled_df"
      ],
      "metadata": {
        "id": "N7yAOdD-C17y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XGjP5pY1DOKC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
